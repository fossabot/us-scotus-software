#!/usr/bin/python
# -*- coding: utf-8 -*-

#
# Copyright (c) 2016 the authors of the https://github.com/publicdocs project.
# Use of this file is subject to the NOTICE file in the root of the repository.
#


import requests
import json
import urllib2
import urllib
import hashlib
import os
import gzip
import codecs
import zlib
import argparse
import shutil
import StringIO
import time
import zipfile
import subprocess

from xml.sax.saxutils import escape
from xml.etree import ElementTree
from string import Template
from collections import namedtuple
from multiprocessing import Pool


_out_readme_markdown = Template(u"""---
---

# $fancytitle

* Portions Copyright Â© 2016 the authors of the https://github.com/publicdocs project. No claim made to original US government works.
  Use of this file is subject to the [NOTICE](https://github.com/publicdocs/notice/blob/master/NOTICE).
* See the [Document Metadata](#document-metadata) below for more information.
  This file is generated from historical government data; content and/or formatting may be inaccurate and out-of-date and should not be used for official purposes.

----------

$innercontent

----------

## Document Metadata

This is a modified, processed, unofficial, and marked-up version of a US Supreme Court slip opinion,
generated by the https://github.com/publicdocs project.

* Original provenance
    * URL: $url
    * SHA 512 digest = $sha512

For more information on the original source, see:
https://www.supremecourt.gov/opinions/opinions.aspx

""")



# First we run pdf2txt as a shell command.  This pdf2txt comes from:
# https://github.com/euske/pdfminer/commit/14fd0fd2d6ef4e709731377decc6a8c119e5e9d6
#

TextElem = namedtuple("TextElem", "content font size")
TextElem.__new__.__defaults__ = (None, ) * len(TextElem._fields)

Processed = namedtuple("Processed", "texts")


def prep_output(wd):
    wdir = wd + '/gen'
    if os.path.exists(wdir):
        shutil.rmtree(wdir)
    os.makedirs(wdir)

_quotes = {'"': "&quot;", "'": "&apos;"}
def html_escape(t):
    return escape(t, _quotes)

def get_text(elem):
    tag = elem.tag
    text = elem.text
    attrib = elem.attrib
    tail = elem.tail
    # Rule: Any text content must NOT be escaped.
    outputs = []

    if tag == u"text":
        if text:
            f = None
            s = None
            if elem.get(u'font'):
                f = unicode(elem.get(u'font'))
            if elem.get(u'size'):
                s = float(elem.get(u'size'))
            outputs.append(TextElem(content = unicode(text), font = f, size = s))
        assert(len(elem) == 0)
    else:
        for child in elem:
            p = get_text(child)
            for txtp in p.texts:
                if not txtp:
                    continue
                outputs.append(txtp)


    retp = Processed(texts = outputs)
    return retp


def md_fancy(cid):
    return cid


def dir_safe_uslm_id(cid):
    if u":" in cid:
        print u"(FATAL) #### Cannot have ':' in identifier " + cid
        assert(False)
        sys.exit(2)
        return
    if u"*" in cid:
        print u"(FATAL) #### Cannot have '*' in identifier " + cid
        assert(False)
        sys.exit(2)
        return
    if u"$" in cid:
        print u"(FATAL) #### Cannot have '$' in identifier " + cid
        assert(False)
        sys.exit(2)
        return
    if u"@" in cid:
        print u"(FATAL) #### Cannot have '@' in identifier " + cid
        assert(False)
        sys.exit(2)
        return
    if u".." == cid or u"/../" == cid or u"/.." in cid or u"../" in cid:
        print u"(FATAL) #### Cannot have '..' in identifier " + cid
        assert(False)
        sys.exit(2)
        return
    if cid.startswith(u".") or cid.endswith(u"."):
        print u"(FATAL) #### Cannot start or end with '.' in identifier " + cid
        assert(False)
        sys.exit(2)
        return
    return cid

def file_safe_uslm_id(cid):
    cid = cid.replace(u'/', u'_').replace(u':', u'_').replace(u'*', u'_').replace(u'$', u'_')

    if u"/" in cid:
        print u"(FATAL) #### Cannot have '/' in identifier " + cid
        assert(False)
        sys.exit(2)
        return
    if u".." == cid or u"/../" == cid or u"/.." in cid or u"../" in cid:
        print u"(FATAL) #### Cannot have '..' in identifier " + cid
        assert(False)
        sys.exit(2)
        return
    return cid


# No links, images, or html tags. Don't auto bold or italics either
_md_escape_chars = list(u'\\`_{}[]<>*_')
def md_escape(txt):
    ret = u""
    for c in txt:
        if c in _md_escape_chars:
            ret = ret + "\\"
        ret = ret + c
    return ret

def process_pdf(pdffn, wd):
    hasher = hashlib.sha512()
    with open(pdffn, 'rb') as input_pdf:
        hasher.update(input_pdf.read())
    sha = hasher.hexdigest()

    wdir = wd + u'/gen/xml/'
    issues = u''
    if os.path.exists(wdir):
        shutil.rmtree(wdir)
    os.makedirs(wdir)
    # pdf2txt.py -c utf-8 -t xml assets/pdf/slips2015/docket_slip_opinion__13-1067.pdf > assets/xml/slips2015/docket_slip_opinion__13-1067.xml
    op = subprocess.check_output([u'/usr/bin/python', u'/usr/local/bin/pdf2txt.py', u'-c', u'utf-8', u'-t', u'xml', pdffn])
    of = wdir + u'/tmpxml.xml'
    f = open(of, 'wb')
    f.write(unicode(op.decode('utf-8')).encode('utf-8'))
    f.close()
    return [unicode(op.decode('utf-8')), sha]


NBSP = u"\u00A0"

def process_xml(pdfinfo, wd):
    pdftext = pdfinfo[0]
    pdfsha = pdfinfo[1]
    wdir = wd + u'/gen/slips/dockets/'
    issues = u''
    if os.path.exists(wdir):
        shutil.rmtree(wdir)
    os.makedirs(wdir)
    of = wdir + u'/index.md'

    try:
        origxml = ElementTree.fromstring(pdftext.encode('utf-8'))
    except:
        print u"(FATAL) #### FAILURE TO PARSE "
        raise

    p = get_text(origxml)
    old_texts = p.texts
    old_texts.append(TextElem(content = u'', font = '_END_', size = 1))
    last_content = u''
    last_font = None
    last_size = None

    grouped = []

    for elem in old_texts:
        if elem.font and not last_font:
            last_font = elem.font
        if elem.size and not last_size:
            last_size = elem.size
        if elem.font and elem.size and (elem.font != last_font) and (elem.size != last_size):
            grouped.append(TextElem(content = last_content, font = last_font, size = last_size))
            last_content = u''
            last_size = elem.size
            last_font = elem.font
        last_content = last_content + elem.content

    out = u''
    for elem in grouped:
        pre = u''
        post = u''
        if u'Italic' in elem.font:
            pre = pre + u'_'
            post = u'_' + post
        if u'Bold' in elem.font:
            pre = pre + u'**'
            post = u'**' + post
        if elem.size < 10:
            pre = pre + u'<sup>'
            post = u'</sup>' + post
        to = elem.content
        if to.strip():
            while to.startswith(u'\n') or to.startswith(u' '):
                pre = to[0] + pre
                to = to[1:]
            while to.endswith(u'\n') or to.endswith(u' '):
                post = post + to[-1]
                to = to[:-1]
            while u'  ' in to:
                to = to.replace(u'  ', u' ')
            out = out + pre + md_escape(to) + post
        else:
            out = out + to

    # << 11 size for tiny headers
    # 9.048 for footnotes

    o2 = u''
    for l in out.splitlines():
        l = l.strip()
        if l == u"Opinion of the Court" or l == u'Dissent' or l==u'Concurrence' or l ==u'Syllabus':
            l = u'\n' + (NBSP * 20) + l + u'\n'
        o2 = o2 + l + u'\n'

    fancytitle = 'docket'

    fc = _out_readme_markdown.substitute(
            url = u"https://supremecourt.gov",
            innercontent = o2,
            sha512 = pdfsha,
            fancytitle = fancytitle,
    )
    f = open(of, 'w')
    f.write(fc.encode('utf-8'))
    f.close()


def main():
    parser = argparse.ArgumentParser(description='Generate Markdown from SCOTUS slip opinion PDFs.')
    parser.add_argument('--wd', '--working-dir', dest='working_directory', action='store',
                        default='working/',
                        help='working directory for temporary files generated by processing')
    parser.add_argument('--i', '--input-pdf', dest='input_pdf', action='store', type=str,
                        help='path to input zip file')

    args = parser.parse_args()
    if args.input_pdf:
        prep_output(args.working_directory)
        pdfinfo = process_pdf(args.input_pdf, args.working_directory)
        process_xml(pdfinfo, args.working_directory)
    else:
        print u"(FATAL) #### Could not determine operating mode"
        assert(False)

if __name__ == "__main__":
    main()
